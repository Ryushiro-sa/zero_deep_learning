{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"section6.ipynb","provenance":[],"authorship_tag":"ABX9TyNzIIoZQ7jVMoymCGcn/BnT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 6章 学習に関するテクニック<165>"],"metadata":{"id":"OwBphcLNZkyf"}},{"cell_type":"markdown","source":["## 6.1 パラメータの更新<165>"],"metadata":{"id":"bpUYQVYqZk2N"}},{"cell_type":"markdown","source":["NNの学習の目的は、損失関数の値をできるだけ小さくするパラメータを発見すること。\n","\n","これは、最適なパラメータを見つける問題で、そのような問題を解くことを**最適化**という。\n","\n","NNではパラメータが膨大すぎるが、やみくもに求めるよりSGDを用いて計算することで効率的に最適なパラメータに向かっていたね。\n","\n","だがしかし、SGDにも欠点はある。SGDの欠点を指摘しつつ、別の最適化手法を紹介しよう。"],"metadata":{"id":"1LrkMfPHavpm"}},{"cell_type":"markdown","source":["### 6.1.1 冒険家の話"],"metadata":{"id":"TLpf60YBZk5P"}},{"cell_type":"markdown","source":["### 6.1.2 SGD<166>"],"metadata":{"id":"lRMcTDWfZk7f"}},{"cell_type":"markdown","source":["### 6.1.3 SGDの欠点<168>"],"metadata":{"id":"PqZC8QFAZk-k"}},{"cell_type":"markdown","source":["SGDが非効率な例を挙げる\n","\n","以下の式(6.2)の最小値を求める問題を考える\n","\n","$$f(x,y) = \\frac{1}{20}x^{2} + y^{2} \\hspace{10mm}(6.2)$$\n","\n","このグラフはお椀をx軸方向に伸ばしたような形。\n","\n","こいつの勾配を求めてみると以下図のようになる\n","\n","多くの場所で最小値(0,0)を刺さない悲しい感じ。\n","\n","実際に(-7,2)を初期値としてSGDを適応してみると以下のようになる。\n","\n","\n","これからSGDの欠点は、関数が伸びた形だと、勾配が本来の最小値方向を示さず、非効率な経路で探索することになる。"],"metadata":{"id":"4MtFJcvJZlcm"}},{"cell_type":"markdown","source":["### 6.1.4 Momentum<170>"],"metadata":{"id":"zLRfV7l_ZlfL"}},{"cell_type":"markdown","source":["SGDに代わる手法の一つ。Momentumとは、「運動量」という意味。\n","\n","以下の数式で表される\n","\n","$$\\mathbf{v} \\leftarrow \\alpha\\mathbf{v} - \\eta \\frac{\\partial L}{\\partial W} \\hspace{10mm} (6.3)$$\n","$$W \\leftarrow W + \\mathbf{v} \\hspace{10mm}(6.4)$$\n","\n","$W$は更新する重みパラメータ\n","\n","$\\frac{\\partial L}{\\partial W}$は、$W$に関する損失関数の勾配\n","\n","$\\eta$は学習係数\n","\n","$\\mathbf{v}$は「物理」でいうところの速度\n","\n","(6.3)式中にある$\\alpha\\mathbf{v}$は、物体が何の力も受けない時に徐々に減速していく役割。(空気抵抗や摩擦みたいなもん)"],"metadata":{"id":"lCd7-YO5ZliE"}},{"cell_type":"code","source":["class Momentum:\n","  def __init_(self, lr=0.01, mometum=0.9):\n","    self.lr = lr\n","    self.momentum = momentum\n","    self.v = None\n","\n","  def update(self, params, grads):\n","    if self.v is None:\n","      self.v = {}\n","      for key, val in params.item():\n","        self.v[key] = np.zeros_like(val)\n","      \n","    for key in params.keys():\n","      self.v[key] = self.momentum*self.v[key] - self.lr*grads[key]"],"metadata":{"id":"gHlEsmQlWK_x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["class Momentum:"],"metadata":{"id":"MdIV7zqEZllV"}},{"cell_type":"markdown","source":["### 6.1.5 AdaGrad<172>"],"metadata":{"id":"7lVRxr2uZln7"}},{"cell_type":"markdown","source":["学習係数が小さいと、学習に時間がかかりすぎる\n","\n","学習係数が大きいと、発散して正しく学習ができない。\n","\n","この、学習係数に関するテクニックに**学習係数の減衰**というものがある。\n","\n","最初は大きく、徐々に小さくして行くという方法である。\n","\n","AdaGradでは、「全体」の学習係数を一括して小さくするのではなく、「ひとつひとつ」のパラメータに対してちいさくする。オーダーメイド\n","\n"],"metadata":{"id":"RICmSkemZlqP"}},{"cell_type":"markdown","source":["AdaGradの更新方法は以下の数式でかける。\n","\n","$$h ← h + \\frac{\\partial L}{\\partial W} \\textcircled{・} \\frac{\\partial L}{\\partial W} \\hspace{10mm}(6.5)$$\n","$$W ← W - \\eta \\frac{1}{\\sqrt{h}} \\frac{\\partial L}{\\partial W} \\hspace{10mm} (6.6)$$\n","\n","$h$はこれまで経験した勾配の値を２乗和として保持。\n","\n","パラメータ更新の際に$\\frac{1}{\\sqrt{h}}$をかけることでスケールを調整している。これにより、パラメータの要素の中でもよく動いた要素は学習係数がちいさくなる。"],"metadata":{"id":"LNvLfGnOmt7v"}},{"cell_type":"code","source":["class AdaGrad:\n","  def __init__(self, lr=0.01):\n","    self.lr = lr\n","    self.h = None\n","\n","  def update(self, prams, grad):\n","    if self.h is None:\n","      self.f = {}\n","      for key, val in params.items():\n","        self.h[key] = np.zeros_like(val)\n","\n","      for key in paramas.keys():\n","        self.h[key] += grads[key] * grads[key]\n","        params[key] -= self.lr * grads[key] /(np.sqrt(self.h[key]) + 1e-7)"],"metadata":{"id":"5nAngnbGsV6i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["圖６−６"],"metadata":{"id":"JWeU9nK4mt57"}},{"cell_type":"markdown","source":["### 6.1.6 Adam<175>"],"metadata":{"id":"IPOhYxY7mt31"}},{"cell_type":"markdown","source":["MomentumとAdaGradを融合するとどうなるのだろうか？それが、Adamのベースアイディア。\n","\n"],"metadata":{"id":"HUGVkWhOmt1f"}},{"cell_type":"markdown","source":["### 6.1.7 どの更新手法を用いるか？<175>"],"metadata":{"id":"yd6jb3P2mtza"}},{"cell_type":"markdown","source":["SGD,Momentum、AdamGrad,Adamとあったが、それぞれの得手不得手があるからどれがいいとかは一概にはいえない"],"metadata":{"id":"Q7fFDC0JmtxT"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"oyjbcOeUmtvO"}},{"cell_type":"markdown","source":["### 6.1.8 Mnistデータセットによる更新手法の比較"],"metadata":{"id":"MRMDkbV-mts5"}},{"cell_type":"markdown","source":["ず６−８"],"metadata":{"id":"z-ZEorkmmtrE"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"ORishV8mmto-"}},{"cell_type":"markdown","source":["## 6.2重みの初期化値<178>"],"metadata":{"id":"9vED12yfmtmp"}},{"cell_type":"markdown","source":["### 6.2.1 重みの初期値を0にする？<178>"],"metadata":{"id":"RDa0JUzGmtk0"}},{"cell_type":"markdown","source":["重みの初期値を０にするのは悪いアイディア。というか、初期値を同じ値にしておくことはとても良くないこと。なぜかというと、誤差逆伝播の時に全ての重みが同じように更新されてしまうので、重みが対称的な同じ値となり、多くの重みを用意する意味がなくなってしまうから。"],"metadata":{"id":"tbBEyaFimtiu"}},{"cell_type":"markdown","source":["### 6.2.2隠れ層のアクティベーション分布<179>"],"metadata":{"id":"5Jac_EpFmtgp"}},{"cell_type":"markdown","source":["隠れ層の活性化関数かました後の分布を観察しよう。\n","\n","それぞれの層は１００個のニューロンを持ち、入力データとして１０００個のデータをガウス分布でランダムに生成した５層NNに流します。\n","\n","活性化関数にはシグモイド関数を使用。重みのスケールは標準偏差１のガウス分布を用いている。\n","\n","するとず６−１０の結果が得られる"],"metadata":{"id":"kqhdrEIjmte0"}},{"cell_type":"markdown","source":["標準偏差を0.01にすると以下の分布になる。"],"metadata":{"id":"zlWpc3zZmtcg"}},{"cell_type":"markdown","source":["では、どんな重みがいいか？「Xavierの初期値」ていうやつが一般的なDLのフレームワークで用いられている。この結果がず６−１３"],"metadata":{"id":"NtPR0Y3xmtap"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"fNYx-fTrmtYl"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"Pt5tMqGDmtWf"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"m7wv7bs-mtUg"}}]}